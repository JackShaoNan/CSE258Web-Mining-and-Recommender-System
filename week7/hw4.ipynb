{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "### Just the first 5000 reviews\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ignore capitalization and remove punctuation\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "for d in data:\n",
    "  r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    #w = stemmer.stem(w) # with stemming\n",
    "    wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. How many unique bigrams are there amongst all of the reviews? \n",
    "# List the 5 most-frequently-occurring bigrams along with their number \n",
    "# of occurrences in the corpus (1 mark).\n",
    "bigramCount = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for i in range(0,len(words)-1):\n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        bigramCount[bigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4587, 'with a')\n",
      "(2595, 'in the')\n",
      "(2245, 'of the')\n",
      "(2056, 'is a')\n",
      "(2033, 'on the')\n"
     ]
    }
   ],
   "source": [
    "biCountList = [(bigramCount[b],b) for b in bigramCount]\n",
    "#sorted(biCountList, key=lambda x: x[0], reverse=True)\n",
    "biCountList.sort()\n",
    "biCountList.reverse()\n",
    "for i in range(5):\n",
    "    print biCountList[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. The code provided performs least squares using the 1000 most \n",
    "#common unigrams. Adapt it to use the 1000 most common bigrams and \n",
    "#report the MSE obtained using the new predictor (use bigrams only, \n",
    "#i.e., not unigrams+bigrams) (1 mark). Note that the code performs \n",
    "#regularized regression with a regularization parameter of 1.0.\n",
    "biwords = [x[1] for x in biCountList[:1000]]\n",
    "biwordId = dict(zip(biwords, range(len(biwords))))\n",
    "biwordSet = set(biwords)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(biwords)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for i in range(0,len(words)-1):\n",
    "        bigram = words[i] + \" \" + words[i+1]\n",
    "        if bigram in biwords:\n",
    "            feat[biwordId[bigram]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X2 = [feature(d) for d in data]\n",
    "y2 = [d['review/overall'] for d in data]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X2, y2)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MSE: 0.34315301406136334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print \"MSE:\", mean_squared_error(y2, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. What is the inverse document frequency of the words ‘foam’, \n",
    "#‘smell’, ‘banana’, ‘lactic’, and ‘tart’? What are their tf-idf \n",
    "#scores in the first review (using log base 10) (1 mark)?\n",
    "from math import log\n",
    "df = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = set(r.split())\n",
    "    for word in words:\n",
    "        df[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word):\n",
    "    return log(len(data) / df[word]*1.0, 10)\n",
    "def tf(word, d):\n",
    "    res = 0\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w == word:\n",
    "            res += 1\n",
    "    return res\n",
    "def tfidf(word, d):\n",
    "    return tf(word,d) * idf(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foam idf: 1.11394335231\n",
      "smell idf: 0.47712125472\n",
      "banana idf: 1.67209785794\n",
      "lactic idf: 2.92064500141\n",
      "tart idf: 1.80617997398\n",
      "foam tfidf in 1st review: 2.22788670461\n",
      "smell tfidf in 1st review: 0.47712125472\n",
      "banana tfidf in 1st review: 3.34419571587\n",
      "lactic tfidf in 1st review: 5.84129000281\n",
      "tart tfidf in 1st review: 1.80617997398\n"
     ]
    }
   ],
   "source": [
    "words = ['foam','smell','banana','lactic','tart']\n",
    "for w in words:\n",
    "    print w + \" idf: \" + str(idf(w))\n",
    "for w in words:\n",
    "    print w + \" tfidf in 1st review: \" + str(tf(w,data[0])*idf(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. What is the cosine similarity between the first and the second \n",
    "#review in terms of their tf-idf representations (considering unigrams\n",
    "#only) (1 mark)?\n",
    "words = [x for x in wordCount]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "def feature6(d):\n",
    "    feat = [0]*len(wordCount)\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        feat[wordId[w]] = tfidf(w,d)\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "X6 = np.array([feature6(d) for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between review 1 and 2: [[0.0673433]]\n"
     ]
    }
   ],
   "source": [
    "print \"Cosine similarity between review 1 and 2:\", cosine_similarity(X6[0:1], X6[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Which other review has the highest cosine similarity compared to \n",
    "#the first review (provide the beerId and profileName, or the text of \n",
    "#the review) (1 mark)?\n",
    "similarities = []\n",
    "for i in range(1,len(data)):\n",
    "    d = data[i]\n",
    "    similarity = cosine_similarity(X6[0:1], X6[i:i+1])\n",
    "    similarities.append((similarity, (d['beer/beerId'])))\n",
    "similarities.sort()\n",
    "similarities.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top cosine similarity: [[0.30083382]]\n",
      "Top beerId: 72146\n"
     ]
    }
   ],
   "source": [
    "print \"Top cosine similarity: \" + str(similarities[0][0])\n",
    "print \"Top beerId: \" + str(similarities[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0007545265679600412\n"
     ]
    }
   ],
   "source": [
    "#6. Adapt the original model that uses the 1000 most common unigrams, \n",
    "#but replace the features with their 1000-dimensional tf-idf \n",
    "#representations, and report the MSE obtained with the new model.\n",
    "y6 = np.array([d['review/overall'] for d in data])\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X6, y6)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X6)\n",
    "print \"MSE:\", mean_squared_error(y6, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19427"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X6[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#7. Implement a validation pipeline for this same data, by randomly shuffling the data, \n",
    "#using 5000 reviews for training, another 5000 for validation, and another 5000 for testing. \n",
    "#Consider regularization parameters in the range {0.01, 0.1, 1, 10, 100}, and report MSEs \n",
    "#on the test set for the model that performs best on the validation set. Using this pipeline, \n",
    "#compare the following alternatives in terms of their performance:\n",
    "# • Unigrams vs. bigrams\n",
    "# • Removing punctuation vs. preserving it. The model that preserves punctuation should treat punc-\n",
    "# tuation characters as separate words, e.g. “Amazing!” would become [‘amazing’, ‘!’]\n",
    "# • tfidf vs. word counts\n",
    "# In total you should compare 2 × 2 × 2 = 8 models, and produce a table comparing their performance (2 marks)\n",
    "print \"Reading data...\"\n",
    "data7 = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:15000]\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.shuffle(data7)\n",
    "train = data7[:5000]\n",
    "valid = data7[5000:10000]\n",
    "test = data7[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "def getTfidf(word, d, inputWords, punc, dataset):\n",
    "    if word in inputWords:\n",
    "        inpu = inputWords[word]\n",
    "        myidf = log(len(dataset)*1.0 / (inpu), 10)\n",
    "    else:\n",
    "        myidf = log(len(dataset) / 1.0, 10)\n",
    "    \n",
    "    mytf = 0\n",
    "    if punc:\n",
    "        r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    else:\n",
    "        l = []\n",
    "        for c in d['review/text'].lower(): \n",
    "            if c in punctuation: \n",
    "                l.append(' '+c) \n",
    "            else: \n",
    "                l.append(c)\n",
    "        r = ''.join(l)\n",
    "    for w in r.split():\n",
    "        if w == word:\n",
    "            mytf += 1\n",
    "    res = mytf * myidf\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get inputWords and inputId\n",
    "def getInput(data, punc, bi, tfidf):\n",
    "    gramCount = defaultdict(int)\n",
    "    for d in data:\n",
    "        if punc:\n",
    "            r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "        else:\n",
    "            l = []\n",
    "            for c in d['review/text'].lower(): \n",
    "                if c in punctuation: \n",
    "                    l.append(' '+c) \n",
    "                else: \n",
    "                    l.append(c)\n",
    "            r = ''.join(l)\n",
    "        words = r.split()\n",
    "        if bi:\n",
    "            for i in range(0,len(words)-1):\n",
    "                bigram = words[i] + \" \" + words[i+1]\n",
    "                gramCount[bigram] += 1\n",
    "        else:\n",
    "            for w in words:\n",
    "                gramCount[w] += 1\n",
    "    counts = [(gramCount[w], w) for w in gramCount]\n",
    "    counts.sort()\n",
    "    counts.reverse()\n",
    "    uni = [x[1] for x in counts[:1000]]\n",
    "    wordId = dict(zip(uni, range(len(uni))))\n",
    "    if tfidf:\n",
    "#         uni = [x for x in gramCount]\n",
    "#         wordId = dict(zip(uni, range(len(uni))))\n",
    "#         return (gramCount, wordId)\n",
    "        wordId = dict(zip(uni, range(len(uni))))\n",
    "        uni = dict(zip(uni, [x[0] for x in counts[:1000]]))\n",
    "    return (uni, wordId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args:\n",
    "# inputWords: \n",
    "# inputId:\n",
    "# punc: remove punc or not\n",
    "# bi: use bi or uni\n",
    "# tfidf: use tfidf or count\n",
    "def feature7(datum, inputWords, inputId, punc, bi, tfidf, dataset):\n",
    "    feat = [0]*len(inputWords)\n",
    "    if punc:\n",
    "        r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    else:\n",
    "        l = []\n",
    "        for c in datum['review/text'].lower(): \n",
    "            if c in punctuation: \n",
    "                l.append(' '+c) \n",
    "            else: \n",
    "                l.append(c)\n",
    "        r = ''.join(l)\n",
    "    words = r.split()\n",
    "    if tfidf:\n",
    "        for w in words:\n",
    "            if w in inputId:\n",
    "                feat[inputId[w]] = getTfidf(w, datum, inputWords, punc, dataset)\n",
    "    else:\n",
    "        if bi:\n",
    "            for i in range(0,len(words)-1):\n",
    "                bigram = words[i] + \" \" + words[i+1]\n",
    "                if bigram in inputId:\n",
    "                    feat[inputId[bigram]] += 1\n",
    "        else:\n",
    "            for w in words:\n",
    "                if w in inputId:\n",
    "                    feat[inputId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args: \n",
    "# args[0] : uni or bi\n",
    "# args[1] : remove punc or not\n",
    "# args[2] : tfidf or not\n",
    "# args[3] : lambda\n",
    "# args[4] : training dataset\n",
    "# args[5] : validation dataset\n",
    "def fun7(args):\n",
    "    inputWords, inputId = getInput(args[4], args[1], args[0], args[2])\n",
    "    X = [feature7(d, inputWords, inputId, args[1], args[0], args[2], args[4]) for d in args[4]]\n",
    "    y = np.array([d['review/overall'] for d in args[4]])\n",
    "    clf = linear_model.Ridge(args[3], fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    theta = clf.coef_\n",
    "    \n",
    "    inputWords2, inputId2 = getInput(args[5], args[1], args[0], args[2])\n",
    "    X2 = [feature7(d, inputWords2, inputId2, args[1], args[0], args[2], args[5]) for d in args[5]]\n",
    "    y2 = np.array([d['review/overall'] for d in args[5]])\n",
    "    \n",
    "    predictions = clf.predict(X2)\n",
    "    return mean_squared_error(y2, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "res1 = defaultdict(list)\n",
    "# lamda = 0.01\n",
    "args = [0, 0, 0, 0.01, train, valid]\n",
    "res1[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 0, 0.01, train, valid]\n",
    "res1[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 1, 0, 0.01, train, valid]\n",
    "res1[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 0, 1, 0.01, train, valid]\n",
    "# res[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 0, 0.01, train, valid]\n",
    "res1[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 1, 1, 0.01, train, valid]\n",
    "# res[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 1, 0.01, train, valid]\n",
    "res1[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 1, 0.01, train, valid]\n",
    "res1[fun7(args)] = args[:4]\n",
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "res2 = defaultdict(list)\n",
    "# lamda = 0.1\n",
    "args = [0, 0, 0, 0.1, train, valid]\n",
    "res2[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 0, 0.1, train, valid]\n",
    "res2[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 1, 0, 0.1, train, valid]\n",
    "res2[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 0, 1, 0.1, train, valid]\n",
    "# res2[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 0, 0.1, train, valid]\n",
    "res2[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 1, 1, 0.1, train, valid]\n",
    "# res2[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 1, 0.1, train, valid]\n",
    "res2[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 1, 0.1, train, valid]\n",
    "res2[fun7(args)] = args[:4]\n",
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "res3 = defaultdict(list)\n",
    "# lamda = 1.0\n",
    "args = [0, 0, 0, 1.0, train, valid]\n",
    "res3[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 0, 1.0, train, valid]\n",
    "res3[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 1, 0, 1.0, train, valid]\n",
    "res3[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 0, 1, 1.0, train, valid]\n",
    "# res3[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 0, 1.0, train, valid]\n",
    "res3[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 1, 1, 1.0, train, valid]\n",
    "# res3[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 1, 1.0, train, valid]\n",
    "res3[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 1, 1.0, train, valid]\n",
    "res3[fun7(args)] = args[:4]\n",
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "res4 = defaultdict(list)\n",
    "# lamda = 10.0\n",
    "args = [0, 0, 0, 10.0, train, valid]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 0, 10.0, train, valid]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 1, 0, 10.0, train, valid]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 0, 1, 10.0, train, valid]\n",
    "# res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 0, 10.0, train, valid]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 1, 1, 10.0, train, valid]\n",
    "# res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 1, 10.0, train, valid]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 1, 10.0, train, valid]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "res5 = defaultdict(list)\n",
    "# lamda = 100.0\n",
    "args = [0, 0, 0, 100.0, train, valid]\n",
    "res5[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 0, 100.0, train, valid]\n",
    "res5[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 1, 0, 100.0, train, valid]\n",
    "res5[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# args = [0, 0, 1, 100.0, train, valid]\n",
    "# res5[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 0, 100.0, train, valid]\n",
    "res5[fun7(args)] = args[:4]\n",
    "print 1\n",
    "# arg5 = [0, 1, 1, 100.0, train, valid]\n",
    "# res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 1, 100.0, train, valid]\n",
    "res5[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 1, 100.0, train, valid]\n",
    "res5[fun7(args)] = args[:4]\n",
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"uni/bi\\tpunc?\\ttfidf?\\tlambda\\tmse\")\n",
    "print (str(p)+'\\t\\t'+str(n)+'\\t\\t'+str(tp)+'\\t\\t'+str(tn)+'\\t\\t'+str(fp)+'\\t\\t'+str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [1, 1, 1, 0.01, train, valid]\n",
    "res[fun7(args)] = args[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5970640025038999, [1, 1, 1, 0.01])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(min(res1),res1[min(res1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5967228452077881, [1, 1, 1, 10.0])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = [(min(res1),res1[min(res1)]), (min(res2),res2[min(res2)]), (min(res3),res3[min(res3)]), (min(res4),res4[min(res4)]), (min(res5),res5[min(res5)])]\n",
    "min(mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5967228452077881, [1, 1, 1, 10.0])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# best lambda = 10.0\n",
    "res7 = defaultdict(list)\n",
    "# lamda = 10.0\n",
    "args = [0, 0, 0, 10.0, train, test]\n",
    "res7[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 0, 10.0, train, test]\n",
    "res7[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 1, 0, 10.0, train, test]\n",
    "res7[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 0, 1, 10.0, train, test]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 0, 10.0, train, test]\n",
    "res7[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [0, 1, 1, 10.0, train, test]\n",
    "res4[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 0, 1, 10.0, train, test]\n",
    "res7[fun7(args)] = args[:4]\n",
    "print 1\n",
    "args = [1, 1, 1, 10.0, train, test]\n",
    "res7[fun7(args)] = args[:4]\n",
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0.581299851195812: [1, 1, 1, 10.0],\n",
       "             0.5967228452077881: [1, 0, 1, 10.0],\n",
       "             0.6864335242537983: [1, 1, 0, 10.0],\n",
       "             0.729615915571554: [0, 1, 1, 10.0],\n",
       "             0.7341914781601425: [0, 1, 0, 10.0],\n",
       "             0.7654271995308849: [0, 0, 1, 10.0],\n",
       "             0.7884975249979896: [1, 0, 0, 10.0]})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
