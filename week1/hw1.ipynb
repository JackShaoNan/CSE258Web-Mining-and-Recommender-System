{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 211,\n",
       " 1.5: 343,\n",
       " 2.0: 1099,\n",
       " 2.5: 1624,\n",
       " 3.0: 4137,\n",
       " 3.5: 8797,\n",
       " 4.0: 16575,\n",
       " 4.5: 12883,\n",
       " 5.0: 4331}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. What is the distribution of ratings in the dataset (for ‘review/taste’)? \n",
    "# That is, how many 1-star, 2-star, 3-star (etc.) reviews are there? You may \n",
    "# write out the values or include a simple plot (1 mark).\n",
    "def dis_rate(datam):\n",
    "    res = {1.0:0, 1.5:0, 2.0:0, 2.5:0, 3.0:0, 3.5:0, 4.0:0, 4.5:0, 5.0:0}\n",
    "    for d in data: \n",
    "      if d.has_key('review/taste'):\n",
    "        res[d['review/taste']] = res[d['review/taste']] + 1\n",
    "    return res\n",
    "res = dis_rate(data)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11795084, -0.05637406,  0.10877902])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Train a simple predictor to predict a beer’s ‘taste’ score using two \n",
    "# features: review/taste ≃ θ0 + θ1 × [beer is a Hefeweizen] + θ2 × beer/ABV \n",
    "# Report the values of θ0, θ1, and θ2. Briefly describe your interpretation \n",
    "# of these values, i.e., what do θ0, θ1, and θ2 represent (1 mark)?\n",
    "def feature(datam):\n",
    "    feat = [1]\n",
    "    if datam['beer/style'] == \"Hefeweizen\":\n",
    "        feat.append(1)\n",
    "    else:\n",
    "        feat.append(0)\n",
    "    feat.append(datam['beer/ABV'])\n",
    "    return feat\n",
    "X = [feature(d) for d in data]\n",
    "Y = [d['review/taste'] for d in data]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, Y, rcond = -1)\n",
    "theta\n",
    "# The euqation can be represented in : \n",
    "# review/taste = [θ0, θ1, θ2].[1, isHefeweizen, beer/ABV]\n",
    "# if beer is Hefeweizen, θ1 = 1 else θ1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.99691466 -0.03573098  0.11672256]\n",
      "0.48396805601335435\n",
      "0.4237065211985192\n"
     ]
    }
   ],
   "source": [
    "# 3. Split the data into two equal fractions – the first half for training, \n",
    "# the second half for testing (based on the order they appear in the file). \n",
    "# Train the same model as above on the training set only. What is the model’s \n",
    "# MSE on the training and on the test set (1 mark)?\n",
    "length = len(data)\n",
    "train = data[:length/2]\n",
    "test = data[length/2:length]\n",
    "X = [feature(d) for d in train]\n",
    "Y = [d['review/taste'] for d in train]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, Y, rcond = -1)\n",
    "print theta\n",
    "# MSE for train\n",
    "def MSE(data, theta): \n",
    "    res = 0\n",
    "    for d in data:\n",
    "        f = feature(d)\n",
    "        res = res + numpy.square(d['review/taste'] - \n",
    "                                 (theta[0] + theta[1]*f[1] + theta[2]*f[2]))\n",
    "    res = res / len(data)\n",
    "    return res\n",
    "print MSE(train, theta)\n",
    "print MSE(test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4497756590511239\n",
      "0.4496039833467828\n"
     ]
    }
   ],
   "source": [
    "# 4. Using the first half for training and the second half for testing may \n",
    "# lead to unexpected results (e.g. the training error could be higher than \n",
    "# the test error). \n",
    "# Repeat the above experiment by using a random 50% split of the data \n",
    "# (i.e., half for training, half for testing, after first shuffling the data). \n",
    "# Report the MSE on the train and test set, and suggest one possible reason \n",
    "# why the result may be different from the previous experiment (1 mark).\n",
    "rand_data = numpy.copy(data)\n",
    "mse_train = 0\n",
    "mse_test = 0\n",
    "for i in range(100):\n",
    "    numpy.random.shuffle(rand_data)\n",
    "    train = rand_data[:length/2]\n",
    "    test = rand_data[length/2:length]\n",
    "    X = [feature(d) for d in train]\n",
    "    Y = [d['review/taste'] for d in train]\n",
    "    theta,residuals,rank,s = numpy.linalg.lstsq(X, Y, rcond = -1)\n",
    "    mse_train = mse_train + MSE(train, theta)\n",
    "    mse_test = mse_test + MSE(test, theta)    \n",
    "print mse_train / 100\n",
    "print mse_test / 100\n",
    "# the mse for test set is closer to mse for train set than previous, this happens \n",
    "# because the shuffled data are more irregular and less predictable, so we got bigger\n",
    "# mse in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4489805618904388\n",
      "0.4504005822900977\n"
     ]
    }
   ],
   "source": [
    "# 5. Modify your experiment from Question 4 to use the features \n",
    "# review/taste ≃ θ0 + θ1 × [ABV if beer is a Hefeweizen] + \n",
    "# θ2 × [ABV if beer is not a Hefeweizen]\n",
    "# e.g. the first beer in the dataset would have feature [1, 5.0, 0] \n",
    "# since the beer is a Hefeweizen. Report the training and testing MSE \n",
    "# of this method (1 mark).\n",
    "rand_data = numpy.copy(data)\n",
    "mse_train = 0\n",
    "mse_test = 0\n",
    "length = len(rand_data)\n",
    "def feature(datam):\n",
    "    feat = [1]\n",
    "    if datam['beer/style'] == \"Hefeweizen\":\n",
    "        feat.append(datam['beer/ABV'])\n",
    "        feat.append(0)\n",
    "    else:\n",
    "        feat.append(0)\n",
    "        feat.append(datam['beer/ABV'])\n",
    "    return feat\n",
    "for i in range(100):\n",
    "    numpy.random.shuffle(rand_data)\n",
    "    train = rand_data[:length/2]\n",
    "    test = rand_data[length/2:length]\n",
    "    X = [feature(d) for d in train]\n",
    "    Y = [d['review/taste'] for d in train]\n",
    "    theta,residuals,rank,s = numpy.linalg.lstsq(X, Y, rcond = -1)\n",
    "    mse_train = mse_train + MSE(train, theta)\n",
    "    mse_test = mse_test + MSE(test, theta)\n",
    "print mse_train / 100\n",
    "print mse_test / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. The model from Question 5 uses the same two features as the model \n",
    "# from Questions 2-4 and has the same dimensionality. Comment on why the \n",
    "# two models might perform differently (1 mark).\n",
    "\n",
    "# Answer： Although they both have ABV and style, they are just in \n",
    "# different forms(eg: when beer/style = Hefeweizen, feature in Q5 is \n",
    "# [1,ABV,0], while feature in Q4 is [1,1,ABV]). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98792\n",
      "0.98736\n"
     ]
    }
   ],
   "source": [
    "# 7. First, let’s train a predictor that estimates whether a beer is a \n",
    "# ‘Hefeweizen’ using five features describing its rating:[‘review/taste’,\n",
    "# ‘review/appearance’, ‘review/aroma’, ‘review/palate’, ‘review/overall’].\n",
    "# Train your predictor using an SVM classifier (see the code provided in class). \n",
    "# Use a random split of the data as we did in Question 4. Use a regularization \n",
    "# constant of C = 1000 as in the code stub. What is the accuracy \n",
    "# (percentage of correct classifications) of the predictor on the train and test data? (1 mark)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rand_data = numpy.copy(data)\n",
    "length = len(rand_data)\n",
    "X = [[d['review/taste'],d['review/appearance'],d['review/aroma'],\n",
    "      d['review/palate'],d['review/overall'],] for d in rand_data]\n",
    "Y = [\"Hefeweizen\" in d['beer/style'] for d in rand_data]\n",
    "X_train = X[:length/2]\n",
    "Y_train = Y[:length/2]\n",
    "X_test = X[length/2:]\n",
    "Y_test = Y[length/2:]\n",
    "# svm modle\n",
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy_train = accuracy_score(train_predictions, Y_train)\n",
    "accuracy_test = accuracy_score(test_predictions, Y_test)\n",
    "print accuracy_train\n",
    "print accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98936\n",
      "0.98768\n"
     ]
    }
   ],
   "source": [
    "# 8. Considering same prediction problem as above, can you come up \n",
    "# with a more accurate predictor (e.g. using features from the text, \n",
    "# or otherwise)? Write down the feature vector you design, and report \n",
    "# its train/test accuracy (1 mark).\n",
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# I use review/taste, beer/ABV and  \"Hefeweizen\" in'review/text' to \n",
    "# form the feature\n",
    "rand_data = numpy.copy(data)\n",
    "length = len(rand_data)\n",
    "X = [[d['review/taste'],d['beer/ABV'], \"Hefeweizen\" in d['review/text']] \n",
    "     for d in rand_data]\n",
    "Y = [\"Hefeweizen\" in d['beer/style'] for d in rand_data]\n",
    "X_train = X[:length/2]\n",
    "Y_train = Y[:length/2]\n",
    "X_test = X[length/2:]\n",
    "Y_test = Y[length/2:]\n",
    "# svm modle\n",
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy_train = accuracy_score(train_predictions, Y_train)\n",
    "accuracy_test = accuracy_score(test_predictions, Y_test)\n",
    "print accuracy_train\n",
    "print accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
